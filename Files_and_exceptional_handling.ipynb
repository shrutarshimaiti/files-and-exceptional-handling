{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1.Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "HRu914jVUUER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A-Scenarios Where Multithreading is Preferable to Multiprocessing\n",
        "I/O-Bound Tasks: Multithreading is best suited for programs that perform multiple I/O operations, such as reading/writing files, making network requests, or interacting with databases. In these cases, the threads can switch context during I/O waits, leading to efficient resource usage.\n",
        "\n",
        "Shared Memory: If the threads need to access and modify shared memory frequently, using multithreading can be more efficient due to shared memory space, which avoids the overhead of creating and managing separate memory spaces for processes.\n",
        "\n",
        "Lightweight Tasks: Multithreading is ideal for lightweight tasks that require frequent context switching. The overhead for thread creation and context switching is less than that of processes, making it a better choice when dealing with numerous small operations.\n",
        "\n",
        "Low CPU Utilization: When CPU utilization is not a concern, multithreading is preferable as it involves fewer resources. For example, a GUI application that handles user events (like mouse clicks and keypresses) typically uses multithreading to manage event-driven tasks.\n",
        "Scenarios Where Multiprocessing is Preferable to Multithreading\n",
        "CPU-Bound Tasks: For compute-intensive tasks, multiprocessing is better because it can utilize multiple cores of the CPU. Each process runs independently, ensuring the Global Interpreter Lock (GIL) in Python does not limit performance, as it often does in multithreading.\n",
        "\n",
        "Isolation of Processes: If you need better fault tolerance and isolation between tasks (e.g., different parts of a web service), multiprocessing is a safer choice. One crashing process will not bring down the entire application.\n",
        "\n",
        "High Memory Usage: For tasks that are memory-intensive, separate processes ensure that the memory of each task is managed independently. This approach prevents potential issues caused by multiple threads competing for the same resources.\n",
        "\n",
        "Scalability: In scenarios where scaling the computation across multiple machines or cores is a requirement, multiprocessing provides better options for distributing and managing independent processes."
      ],
      "metadata": {
        "id": "8oHLQlaLUXYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "A-A Process Pool is a collection of worker processes that are used to execute multiple tasks in parallel, typically in a producer-consumer pattern. It provides a way to manage a group of worker processes efficiently, making it easier to distribute tasks across multiple CPU cores. Using a process pool simplifies parallel execution and resource management, allowing developers to focus on task logic rather than process management details.\n",
        "\n",
        "Why Use a Process Pool?\n",
        "Task Management Simplification: The process pool handles the creation, execution, and termination of worker processes, reducing the need for manually managing each process.\n",
        "\n",
        "Reusability of Workers: Instead of creating a new process for each task, a pool of worker processes can be reused, minimizing the overhead of process creation and destruction.\n",
        "\n",
        "Concurrency Control: By limiting the number of processes in the pool, it prevents system resource exhaustion and ensures that only a specified number of processes are running simultaneously.\n",
        "\n",
        "Load Balancing: Process pools distribute the workload evenly across multiple processes, providing a built-in mechanism for balancing load among the workers.\n",
        "\n",
        "Asynchronous Task Execution: Using a pool, you can queue up a number of tasks and have them run asynchronously, with results collected once each task is complete."
      ],
      "metadata": {
        "id": "6PQUMWM3b-wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to be executed in each process\n",
        "def square_number(number):\n",
        "    time.sleep(1)  # Simulating a time-consuming task\n",
        "    return number * number\n",
        "\n",
        "# Main block\n",
        "if __name__ == '__main__':\n",
        "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "    # Create a pool with 4 processes\n",
        "    with Pool(processes=4) as pool:\n",
        "        # Use pool.map to distribute the square_number function across the pool\n",
        "        results = pool.map(square_number, numbers)\n",
        "\n",
        "    print(f\"Square of numbers: {results}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--iukXlAckIR",
        "outputId": "388ee630-7c18-4a09-83f3-65c270301370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Square of numbers: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.Explain what multiprocessing is and why it is used in Python programs.\n",
        "A-Multiprocessing is a parallel programming technique that allows a program to run multiple processes simultaneously. Each process runs independently in its own memory space, and can utilize multiple CPU cores to achieve true parallelism, which is particularly useful for CPU-bound tasks.\n",
        "Use of Multiprocessing-\n",
        "Overcome Python’s GIL Limitation: Python has a Global Interpreter Lock (GIL), which prevents multiple native threads from executing Python bytecode simultaneously in a single process. This means that in multithreading, only one thread can execute Python code at a time. By using multiprocessing, we can bypass this limitation because each process runs its own Python interpreter in its own memory space, allowing true parallel execution.\n",
        "\n",
        "Performance Boost for CPU-Bound Tasks: For tasks that require a lot of computation (e.g., mathematical computations, data analysis), using multiprocessing can significantly speed up execution by utilizing multiple CPU cores.\n",
        "\n",
        "Isolation of Tasks: Processes are isolated from each other. If one process crashes, it does not affect others, making multiprocessing more robust for handling critical operations.\n",
        "\n",
        "Concurrent I/O Operations: While threads are more commonly used for I/O-bound tasks, multiprocessing can still be useful if these tasks need to be handled independently without interference (e.g., multiple processes handling distinct network connections)."
      ],
      "metadata": {
        "id": "koPxB4Cfc0G0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock.\n",
        "A-"
      ],
      "metadata": {
        "id": "AP8iaqPdeaQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list that both threads will access\n",
        "shared_list = []\n",
        "\n",
        "# Lock object to synchronize access to the shared list\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_to_list():\n",
        "    global shared_list\n",
        "    for _ in range(5):  # Add 5 numbers to the list\n",
        "        number = random.randint(1, 100)  # Generate a random number\n",
        "        with list_lock:  # Acquire the lock before modifying the shared list\n",
        "            print(f\"Adding {number} to the list.\")\n",
        "            shared_list.append(number)\n",
        "        time.sleep(random.random())  # Simulate some delay\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_from_list():\n",
        "    global shared_list\n",
        "    for _ in range(5):  # Try to remove 5 numbers from the list\n",
        "        with list_lock:  # Acquire the lock before accessing the shared list\n",
        "            if shared_list:\n",
        "                number = shared_list.pop(0)  # Remove the first element in the list\n",
        "                print(f\"Removed {number} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting for elements to be added.\")\n",
        "        time.sleep(random.random())  # Simulate some delay\n",
        "\n",
        "# Create and start the threads\n",
        "add_thread = threading.Thread(target=add_to_list)\n",
        "remove_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(f\"Final state of the shared list: {shared_list}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXhyYSqDhAsT",
        "outputId": "823d9846-89ba-49c0-faf7-8ac938936f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 25 to the list.\n",
            "Removed 25 from the list.\n",
            "List is empty, waiting for elements to be added.\n",
            "List is empty, waiting for elements to be added.\n",
            "List is empty, waiting for elements to be added.\n",
            "Adding 19 to the list.\n",
            "Adding 48 to the list.\n",
            "Adding 83 to the list.\n",
            "Adding 48 to the list.\n",
            "Removed 19 from the list.\n",
            "Final state of the shared list: [48, 83, 48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        " A-In Python, threads share the same memory space, making data sharing relatively straightforward. However, this shared memory can lead to race conditions if multiple threads access or modify data simultaneously. The key mechanisms for safe data sharing include:\n",
        "\n",
        "a. Locks:\n",
        "threading.Lock is the primary tool for managing access to shared resources.\n",
        "Using locks ensures that only one thread can access a shared variable at a time, preventing data corruption.\n",
        "b. Queues:\n",
        "queue.Queue is a thread-safe data structure designed for communication between threads.\n",
        "Threads can safely add or remove items from a Queue without needing additional locking mechanisms.\n",
        "Queues are useful for producer-consumer problems.\n",
        "c. Thread-Safe Data Structures:\n",
        "The collections module provides thread-safe data structures like deque which can be used in multithreading scenarios.\n",
        "For more advanced requirements, the queue module offers LifoQueue and PriorityQueue.\n",
        "2. Sharing Data Between Processes:\n",
        "Processes in Python have separate memory spaces, which makes data sharing more challenging compared to threads. However, the multiprocessing module provides several tools to facilitate safe data sharing:\n",
        "\n",
        "a. Multiprocessing Queues:\n",
        "multiprocessing.Queue allows processes to safely exchange data.\n",
        "It’s similar to queue.Queue used in multithreading but designed for inter-process communication.\n",
        "b. Shared Memory Objects:\n",
        "multiprocessing.Value and multiprocessing.Array allow the creation of shared memory objects.\n",
        "These objects can be accessed and modified by multiple processes, enabling direct data sharing.\n",
        "c. Managers:\n",
        "multiprocessing.Manager() provides a way to create shared dictionaries, lists, and other data types that can be safely shared between processes.\n",
        "Managers are powerful but come with more overhead compared to using shared memory directly.\n",
        "3. Using concurrent.futures for Higher-Level Abstractions:\n",
        "The concurrent.futures module provides ThreadPoolExecutor and ProcessPoolExecutor, which handle data sharing and exception management automatically, making it easier to write concurrent programs without manually managing locks or shared memory."
      ],
      "metadata": {
        "id": "y55xKyU_hhAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so.\n",
        "A-1. Exception Handling in Multithreading:\n",
        "a. Using try-except in Threads:\n",
        "In a typical multithreading program, you can wrap the thread’s task in a try-except block to catch exceptions and handle them as needed:In this case, the exception is handled within the thread, preventing it from propagating unexpectedly.\n",
        "\n",
        "b. Custom Thread Class:\n",
        "If you want to propagate exceptions back to the main thread, you can create a custom thread class that captures the exception and raises it when needed:c. Using concurrent.futures.ThreadPoolExecutor:\n",
        "The concurrent.futures module makes it easier to handle exceptions using ThreadPoolExecutor. It wraps the function results in a Future object, which you can query for exceptions:2. Exception Handling in Multiprocessing:\n",
        "Handling exceptions in multiprocessing is slightly different since each process runs in its own memory space. Exceptions raised in child processes do not directly propagate to the parent process.\n",
        "\n",
        "a. Capturing Exceptions Using a Custom Wrapper:\n",
        "One approach is to use a custom wrapper function that captures and returns exceptions along with the actual result:b. Using concurrent.futures.ProcessPoolExecutor:\n",
        "Similar to ThreadPoolExecutor, you can use ProcessPoolExecutor to handle exceptions in processes. This module provides a consistent interface for threads and processes:3. Best Practices for Exception Handling in Concurrent Programs:\n",
        "Use Thread/Process Pools with concurrent.futures:\n",
        "\n",
        "Using concurrent.futures is often recommended because it simplifies exception handling by wrapping tasks in Future objects, making it easy to check for exceptions using the result() method.\n",
        "Log Exceptions Immediately:\n",
        "\n",
        "In a concurrent environment, logging exceptions as soon as they occur helps in debugging. Use the logging module for thread-safe logging.Propagate Exceptions to the Parent Process/Thread:\n",
        "\n",
        "For multiprocessing, consider using a Queue or Pipe to pass exceptions back to the main process, or use a custom Process subclass.\n",
        "Graceful Shutdown and Cleanup:\n",
        "\n",
        "Ensure that exceptions in threads or processes do not leave shared resources (like files or connections) in an inconsistent state. Use try-finally blocks or context managers for proper cleanup.\n",
        "4. Using asyncio for Asynchronous Exception Handling:\n",
        "In asynchronous programming with asyncio, exceptions are handled differently using coroutines. Use try-except blocks inside async functions or handle exceptions when gathering tasks:\n",
        "\n"
      ],
      "metadata": {
        "id": "xRQXGxJmKgxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "hWYRTL4LNCON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "# Define a function to calculate the factorial of a given number\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Create a ThreadPoolExecutor to manage threads\n",
        "with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "    # Submit tasks to the thread pool to calculate factorials for numbers 1 to 10\n",
        "    futures = [executor.submit(factorial, i) for i in range(1, 11)]\n",
        "\n",
        "    # Collect and print the results as they complete\n",
        "    for future in futures:\n",
        "        print(f\"Factorial result: {future.result()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwoHHPbhNRIB",
        "outputId": "e59188ba-e733-4e69-b2f1-04833e50ec37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1\n",
            "Calculating factorial of 2Calculating factorial of 3\n",
            "\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5\n",
            "Calculating factorial of 6\n",
            "Calculating factorial of 7\n",
            "Calculating factorial of 8\n",
            "Calculating factorial of 9\n",
            "Calculating factorial of 10\n",
            "Factorial result: 1\n",
            "Factorial result: 2\n",
            "Factorial result: 6\n",
            "Factorial result: 24\n",
            "Factorial result: 120\n",
            "Factorial result: 720\n",
            "Factorial result: 5040\n",
            "Factorial result: 40320\n",
            "Factorial result: 362880\n",
            "Factorial result: 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)."
      ],
      "metadata": {
        "id": "pNU60kcQNkwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a given number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure execution time with a given pool size\n",
        "def measure_time(pool_size):\n",
        "    with Pool(pool_size) as pool:\n",
        "        start_time = time.time()\n",
        "        results = pool.map(square, range(1, 11))  # Compute squares of numbers from 1 to 10\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Pool Size: {pool_size}, Time Taken: {end_time - start_time:.4f} seconds\")\n",
        "        print(f\"Results: {results}\")\n",
        "\n",
        "# Measure time for different pool sizes\n",
        "for size in [2, 4, 8]:\n",
        "    measure_time(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXzYpYkTNyEA",
        "outputId": "bec844d2-2c57-42aa-89f9-517499319cfc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool Size: 2, Time Taken: 0.0041 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool Size: 4, Time Taken: 0.0034 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool Size: 8, Time Taken: 0.0033 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    }
  ]
}